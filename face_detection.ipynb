{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Detection на WIDER FACE\n",
        "\n",
        "Быстрая проверка качества детекции лиц. Используем Haar Cascade как baseline, потом можно будет сравнить с более современными методами.\n",
        "\n",
        "**Что делаем:**\n",
        "- Берем WIDER FACE датасет\n",
        "- Детектим лица Haar Cascade'ом\n",
        "- Считаем метрики (precision/recall)\n",
        "- Смотрим на скорость работы\n",
        "- Визуализируем результаты\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Убираем лишние предупреждения\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Создаем папку для результатов\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Настройки для красивого отображения\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['image.cmap'] = 'gray'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка данных\n",
        "\n",
        "WIDER FACE лежит в `data/images/`. Загружаем все jpg файлы.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_images(data_dir=\"data/images\"):\n",
        "    \"\"\"Загружаем все jpg файлы из папки\"\"\"\n",
        "    images = glob.glob(f\"{data_dir}/*.jpg\")\n",
        "    print(f\"Найдено {len(images)} изображений\")\n",
        "    return images\n",
        "\n",
        "def load_image(path):\n",
        "    \"\"\"Загружаем одно изображение\"\"\"\n",
        "    return cv2.imread(path)\n",
        "\n",
        "def load_annotations(annos_file=\"data/annos.json\"):\n",
        "    \"\"\"Загружаем аннотации из JSON файла\"\"\"\n",
        "    with open(annos_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    annotations = {}\n",
        "    for item in data:\n",
        "        img_path = item['img_path'].replace('\\\\', '/')  # Исправляем пути для Unix\n",
        "        bboxes = item['annotations']['bbox']\n",
        "        # Фильтруем только валидные аннотации (invalid=0)\n",
        "        valid_boxes = []\n",
        "        for i, bbox in enumerate(bboxes):\n",
        "            if item['annotations']['invalid'][i] == 0:\n",
        "                valid_boxes.append(bbox)\n",
        "        annotations[img_path] = valid_boxes\n",
        "    \n",
        "    print(f\"Загружено аннотаций для {len(annotations)} изображений\")\n",
        "    return annotations\n",
        "\n",
        "# Загружаем данные\n",
        "image_paths = load_images()\n",
        "annotations = load_annotations()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Детектор лиц\n",
        "\n",
        "Используем стандартный Haar Cascade из OpenCV. Быстро, но не самый точный.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загружаем Haar Cascade классификатор\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def detect_faces(image, scale_factor=1.1, min_neighbors=5, min_size=(30, 30)):\n",
        "    \"\"\"Детектим лица на изображении\"\"\"\n",
        "    if image is None:\n",
        "        return []\n",
        "    \n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=scale_factor, \n",
        "                                        minNeighbors=min_neighbors, minSize=min_size)\n",
        "    return faces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Метрики\n",
        "\n",
        "Считаем IoU, precision, recall. Без этого никак.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iou(box1, box2):\n",
        "    \"\"\"Считаем IoU между двумя прямоугольниками\"\"\"\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "    \n",
        "    # Пересечение\n",
        "    x_left = max(x1, x2)\n",
        "    y_top = max(y1, y2)\n",
        "    x_right = min(x1 + w1, x2 + w2)\n",
        "    y_bottom = min(y1 + h1, y2 + h2)\n",
        "    \n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    \n",
        "    intersection = (x_right - x_left) * (y_bottom - y_top)\n",
        "    union = w1 * h1 + w2 * h2 - intersection\n",
        "    \n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def match_boxes(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
        "    \"\"\"Сопоставляем предсказания с ground truth\"\"\"\n",
        "    matches = []\n",
        "    used_gt = set()\n",
        "    \n",
        "    for pred_idx, pred_box in enumerate(pred_boxes):\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        \n",
        "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
        "            if gt_idx in used_gt:\n",
        "                continue\n",
        "                \n",
        "            current_iou = iou(pred_box, gt_box)\n",
        "            if current_iou > best_iou and current_iou >= iou_threshold:\n",
        "                best_iou = current_iou\n",
        "                best_gt_idx = gt_idx\n",
        "        \n",
        "        if best_gt_idx != -1:\n",
        "            matches.append((pred_idx, best_gt_idx, best_iou))\n",
        "            used_gt.add(best_gt_idx)\n",
        "    \n",
        "    matched_pred = {match[0] for match in matches}\n",
        "    unmatched_pred = [i for i in range(len(pred_boxes)) if i not in matched_pred]\n",
        "    unmatched_gt = [i for i in range(len(gt_boxes)) if i not in used_gt]\n",
        "    \n",
        "    return matches, unmatched_pred, unmatched_gt\n",
        "\n",
        "def calculate_metrics(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
        "    \"\"\"Считаем precision, recall, f1\"\"\"\n",
        "    if len(gt_boxes) == 0:\n",
        "        return {\"precision\": 1.0 if len(pred_boxes) == 0 else 0.0, \n",
        "                \"recall\": 1.0, \"f1\": 1.0, \"tp\": 0, \"fp\": len(pred_boxes), \"fn\": 0}\n",
        "    \n",
        "    if len(pred_boxes) == 0:\n",
        "        return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"tp\": 0, \"fp\": 0, \"fn\": len(gt_boxes)}\n",
        "    \n",
        "    matches, unmatched_pred, unmatched_gt = match_boxes(pred_boxes, gt_boxes, iou_threshold)\n",
        "    \n",
        "    tp = len(matches)\n",
        "    fp = len(unmatched_pred)\n",
        "    fn = len(unmatched_gt)\n",
        "    \n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "    \n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"tp\": tp, \"fp\": fp, \"fn\": fn}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Визуализация\n",
        "\n",
        "Рисуем bounding boxes и смотрим что получилось.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_boxes(image, boxes, color=(0, 255, 0), thickness=2):\n",
        "    \"\"\"Рисуем bounding boxes на изображении\"\"\"\n",
        "    result = image.copy()\n",
        "    for x, y, w, h in boxes:\n",
        "        cv2.rectangle(result, (x, y), (x + w, y + h), color, thickness)\n",
        "    return result\n",
        "\n",
        "def show_detection(image, pred_boxes, gt_boxes=None, save_path=None):\n",
        "    \"\"\"Показываем результаты детекции\"\"\"\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    if gt_boxes is not None:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Предсказания\n",
        "        pred_img = draw_boxes(image_rgb, pred_boxes, color=(0, 255, 0))\n",
        "        ax1.imshow(pred_img)\n",
        "        ax1.set_title(f\"Предсказания ({len(pred_boxes)})\")\n",
        "        ax1.axis('off')\n",
        "        \n",
        "        # Ground truth\n",
        "        gt_img = draw_boxes(image_rgb, gt_boxes, color=(255, 0, 0))\n",
        "        ax2.imshow(gt_img)\n",
        "        ax2.set_title(f\"Ground Truth ({len(gt_boxes)})\")\n",
        "        ax2.axis('off')\n",
        "    else:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        pred_img = draw_boxes(image_rgb, pred_boxes, color=(0, 255, 0))\n",
        "        plt.imshow(pred_img)\n",
        "        plt.title(f\"Детекция лиц ({len(pred_boxes)})\")\n",
        "        plt.axis('off')\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Сохранено: {save_path}\")\n",
        "    \n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Тестирование\n",
        "\n",
        "Проверяем на нескольких изображениях как работает детектор.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Тестируем на первых 5 изображениях\n",
        "test_images = image_paths[:5]\n",
        "\n",
        "for i, img_path in enumerate(test_images):\n",
        "    print(f\"\\n--- Изображение {i+1}: {os.path.basename(img_path)} ---\")\n",
        "    \n",
        "    # Загружаем изображение\n",
        "    image = load_image(img_path)\n",
        "    if image is None:\n",
        "        print(\"Не удалось загрузить изображение\")\n",
        "        continue\n",
        "    \n",
        "    # Получаем ground truth\n",
        "    img_key = f\"images/{os.path.basename(img_path)}\"\n",
        "    gt_faces = annotations.get(img_key, [])\n",
        "    \n",
        "    # Детектируем лица\n",
        "    start_time = time.time()\n",
        "    faces = detect_faces(image)\n",
        "    detection_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"Найдено лиц: {len(faces)}\")\n",
        "    print(f\"Ground truth: {len(gt_faces)}\")\n",
        "    print(f\"Время детекции: {detection_time:.3f} сек\")\n",
        "    print(f\"FPS: {1/detection_time:.1f}\")\n",
        "    \n",
        "    # Считаем метрики\n",
        "    if gt_faces:\n",
        "        metrics = calculate_metrics(faces, gt_faces)\n",
        "        print(f\"Precision: {metrics['precision']:.3f}\")\n",
        "        print(f\"Recall: {metrics['recall']:.3f}\")\n",
        "        print(f\"F1: {metrics['f1']:.3f}\")\n",
        "    \n",
        "    # Показываем результат\n",
        "    show_detection(image, faces, gt_faces, save_path=f\"results/detection_{i+1}.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Полная оценка\n",
        "\n",
        "Теперь прогоняем весь датасет и считаем общие метрики.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_dataset(image_paths, annotations, max_images=None):\n",
        "    \"\"\"Оцениваем качество детекции на всем датасете\"\"\"\n",
        "    if max_images:\n",
        "        image_paths = image_paths[:max_images]\n",
        "    \n",
        "    total_faces = 0\n",
        "    total_gt_faces = 0\n",
        "    total_time = 0\n",
        "    all_metrics = []\n",
        "    \n",
        "    print(f\"Обрабатываем {len(image_paths)} изображений...\")\n",
        "    \n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Обработано: {i}/{len(image_paths)}\")\n",
        "        \n",
        "        # Загружаем изображение\n",
        "        image = load_image(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "        \n",
        "        # Получаем ground truth\n",
        "        img_key = f\"images/{os.path.basename(img_path)}\"\n",
        "        gt_faces = annotations.get(img_key, [])\n",
        "        \n",
        "        # Детектируем лица\n",
        "        start_time = time.time()\n",
        "        faces = detect_faces(image)\n",
        "        detection_time = time.time() - start_time\n",
        "        \n",
        "        total_faces += len(faces)\n",
        "        total_gt_faces += len(gt_faces)\n",
        "        total_time += detection_time\n",
        "        \n",
        "        # Считаем метрики\n",
        "        metrics = calculate_metrics(faces, gt_faces)\n",
        "        all_metrics.append(metrics)\n",
        "    \n",
        "    # Общие результаты\n",
        "    avg_faces_per_image = total_faces / len(image_paths)\n",
        "    avg_gt_faces_per_image = total_gt_faces / len(image_paths)\n",
        "    avg_time_per_image = total_time / len(image_paths)\n",
        "    fps = 1 / avg_time_per_image\n",
        "    \n",
        "    # Средние метрики\n",
        "    avg_precision = np.mean([m['precision'] for m in all_metrics])\n",
        "    avg_recall = np.mean([m['recall'] for m in all_metrics])\n",
        "    avg_f1 = np.mean([m['f1'] for m in all_metrics])\n",
        "    \n",
        "    print(f\"\\n=== РЕЗУЛЬТАТЫ ===\")\n",
        "    print(f\"Обработано изображений: {len(image_paths)}\")\n",
        "    print(f\"Всего найдено лиц: {total_faces}\")\n",
        "    print(f\"Всего GT лиц: {total_gt_faces}\")\n",
        "    print(f\"Среднее лиц на изображение: {avg_faces_per_image:.2f}\")\n",
        "    print(f\"Среднее GT лиц на изображение: {avg_gt_faces_per_image:.2f}\")\n",
        "    print(f\"Среднее время на изображение: {avg_time_per_image:.3f} сек\")\n",
        "    print(f\"Средний FPS: {fps:.1f}\")\n",
        "    print(f\"Средняя Precision: {avg_precision:.3f}\")\n",
        "    print(f\"Средняя Recall: {avg_recall:.3f}\")\n",
        "    print(f\"Средняя F1: {avg_f1:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        \"total_images\": len(image_paths),\n",
        "        \"total_faces\": total_faces,\n",
        "        \"total_gt_faces\": total_gt_faces,\n",
        "        \"avg_faces_per_image\": avg_faces_per_image,\n",
        "        \"avg_gt_faces_per_image\": avg_gt_faces_per_image,\n",
        "        \"avg_time_per_image\": avg_time_per_image,\n",
        "        \"fps\": fps,\n",
        "        \"avg_precision\": avg_precision,\n",
        "        \"avg_recall\": avg_recall,\n",
        "        \"avg_f1\": avg_f1\n",
        "    }\n",
        "\n",
        "# Запускаем оценку (ограничиваем 100 изображениями для скорости)\n",
        "results = evaluate_dataset(image_paths, annotations, max_images=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Итоги\n",
        "\n",
        "Haar Cascade работает быстро, но точность не самая высокая. Для продакшена лучше использовать более современные методы.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохраняем результаты\n",
        "with open(\"results/evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Результаты сохранены в results/evaluation_results.json\")\n",
        "\n",
        "# Создаем краткий отчет\n",
        "report = f\"\"\"\n",
        "# Отчет по детекции лиц\n",
        "\n",
        "## Метод: Haar Cascade (OpenCV)\n",
        "\n",
        "## Результаты на {results['total_images']} изображениях:\n",
        "\n",
        "- **Скорость**: {results['fps']:.1f} FPS\n",
        "- **Precision**: {results['avg_precision']:.3f}\n",
        "- **Recall**: {results['avg_recall']:.3f}\n",
        "- **F1-score**: {results['avg_f1']:.3f}\n",
        "\n",
        "## Статистика:\n",
        "- Найдено лиц: {results['total_faces']}\n",
        "- Ground truth лиц: {results['total_gt_faces']}\n",
        "- Среднее лиц на изображение: {results['avg_faces_per_image']:.2f}\n",
        "\n",
        "## Выводы:\n",
        "Haar Cascade показывает базовые результаты. Для улучшения качества рекомендуется использовать более современные методы (RetinaFace, MTCNN, YOLO).\n",
        "\"\"\"\n",
        "\n",
        "with open(\"results/report.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"Отчет сохранен в results/report.md\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
